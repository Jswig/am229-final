@article{boydistributed,
author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
title = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
year = {2011},
issue_date = {January 2011},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {3},
number = {1},
issn = {1935-8237},
url = {https://doi.org/10.1561/2200000016},
doi = {10.1561/2200000016},
abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.},
journal = {Found. Trends Mach. Learn.},
month = jan,
pages = {1–122},
numpages = {122}
}

@article{structuralnonparallel,
title = "Structural nonparallel support vector machine for pattern recognition",
journal = "Pattern Recognition",
volume = "60",
pages = "296 - 305",
year = "2016",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2016.04.017",
url = "http://www.sciencedirect.com/science/article/pii/S0031320316300632",
author = "Dandan Chen and Yingjie Tian and Xiaohui Liu",
keywords = "Structural information, Nonparallel support vector machine, Alternating direction method of multipliers, Pattern recognition",
abstract = "It has been widely accepted that the underlying structural information in the training data within classes is significant for a good classifier in real-world problems. However, existing structural classifiers do not balance structural information׳s relationships both intra-class and inter-class. Combining the structural information with nonparallel support vector machine (NPSVM), we design a new structural nonparallel support vector machine (called SNPSVM). Each model of SNPSVM considers not only the compactness in both classes by the structural information but also the separability between classes, thus it can fully exploit prior knowledge to directly improve the algorithm׳s generalization capacity. Furthermore, we apply the improved alternating direction method of multipliers (ADMM) to SNPSVM. Both our model itself and the solving algorithm can guarantee that it can deal with large-scale classification problems with a huge number of instances as well as features. Experimental results show that SNPSVM is superior to the other current algorithms based on structural information of data in both computation time and classification accuracy."
}

@article{forero2010consensus,
  title={Consensus-Based Distributed Support Vector Machines.},
  author={Forero, Pedro A and Cano, Alfonso and Giannakis, Georgios B},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={5},
  year={2010}
}

@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@article{fan2008liblinear,
  title={LIBLINEAR-A library for large linear classification.(2008)},
  author={Fan, Rong-En and Chang, Kai-Wei and Hsieh, Cho-Jui and Wang, Xiang-Rui and Lin, Chih-Jen},
  journal={The Weka classifier works with version},
  volume={1},
  year={2008}
}

@article{chang2011libsvm,
  title={LIBSVM: A library for support vector machines},
  author={Chang, Chih-Chung and Lin, Chih-Jen},
  journal={ACM transactions on intelligent systems and technology (TIST)},
  volume={2},
  number={3},
  pages={1--27},
  year={2011},
  publisher={Acm New York, NY, USA}
}